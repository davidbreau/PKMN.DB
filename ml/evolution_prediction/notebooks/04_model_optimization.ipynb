{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import math\n",
    "\n",
    "# Définir une fonction pour calculer le RMSE\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Créer un scorer personnalisé\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "rmse_scorer_sklearn = make_scorer(rmse_scorer, greater_is_better=False)\n",
    "\n",
    "# Définir les paramètres à tester (version légère pour réduire le temps de calcul)\n",
    "param_grid = {\n",
    "    'base_estimator__n_estimators': [100, 200],\n",
    "    'base_estimator__learning_rate': [0.1, 0.2],\n",
    "    'base_estimator__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Configurer la validation croisée\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "# Créer le modèle de base\n",
    "base_model = GradientBoostingRegressor(random_state=42)\n",
    "chain_model = RegressorChain(base_model, order=[0, 1, 2, 3, 4], random_state=42)\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=chain_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=rmse_scorer_sklearn,\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Utiliser tous les cœurs disponibles\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données nécessaires\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger le dataset silver\n",
    "silver_df = pl.read_csv('../data/silver_mega_evolutions.csv')\n",
    "\n",
    "# Définir les colonnes à prédire\n",
    "target_cols = [\n",
    "    'evolved_attack', 'evolved_defense', \n",
    "    'evolved_sp_attack', 'evolved_sp_defense', 'evolved_speed'\n",
    "]\n",
    "\n",
    "# Colonnes d'entrée\n",
    "input_cols = [col for col in silver_df.columns if col.startswith('base_')]\n",
    "\n",
    "# Préparer X et y\n",
    "X = silver_df.select(input_cols)\n",
    "y = silver_df.select(target_cols)\n",
    "\n",
    "# Convertir en numpy\n",
    "X_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "# Diviser en train/test\n",
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(X_np, y_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardiser\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_np)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train_np)\n",
    "X_test_scaled = scaler_X.transform(X_test_np)\n",
    "y_test_scaled = scaler_y.transform(y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/21 22:52:26 INFO mlflow.tracking.fluent: Experiment with name 'mega_evolution_optimization' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Configuration de l'expérience MLflow\n",
    "mlflow.set_experiment(\"mega_evolution_optimization\")\n",
    "\n",
    "# Activer l'autologging pour scikit-learn\n",
    "mlflow.sklearn.autolog(log_models=True, log_input_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la recherche d'hyperparamètres pour Gradient Boosting Chain...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/21 22:54:28 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleurs hyperparamètres trouvés:\n",
      "{'base_estimator__learning_rate': 0.2, 'base_estimator__max_depth': 3, 'base_estimator__n_estimators': 100}\n",
      "Meilleur score RMSE (validation croisée): 0.7512\n"
     ]
    }
   ],
   "source": [
    "# Exécuter la recherche par grille avec tracking MLflow\n",
    "with mlflow.start_run(run_name=\"GB_Chain_GridSearch\"):\n",
    "    print(\"Démarrage de la recherche d'hyperparamètres pour Gradient Boosting Chain...\")\n",
    "    \n",
    "    # Log des paramètres de la recherche\n",
    "    mlflow.log_param(\"cv_folds\", cv.n_splits)\n",
    "    mlflow.log_param(\"param_grid\", str(param_grid))\n",
    "    \n",
    "    # Exécuter la recherche\n",
    "    grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "    \n",
    "    # Afficher les meilleurs hyperparamètres\n",
    "    print(\"\\nMeilleurs hyperparamètres trouvés:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"Meilleur score RMSE (validation croisée): {-grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Log des meilleurs paramètres\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        mlflow.log_param(f\"best_{param}\", value)\n",
    "    \n",
    "    # Log du meilleur score\n",
    "    mlflow.log_metric(\"best_cv_rmse\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage de la recherche d'hyperparamètres pour Gradient Boosting Chain...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/21 23:09:06 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleurs hyperparamètres trouvés:\n",
      "{'base_estimator__learning_rate': 0.2, 'base_estimator__max_depth': 3, 'base_estimator__n_estimators': 100}\n",
      "Meilleur score RMSE (validation croisée): 0.7512\n",
      "\n",
      "Résultats des différentes combinaisons d'hyperparamètres:\n",
      "shape: (8, 4)\n",
      "┌─────────────────────────────────┬─────────────────┬────────────────┬─────────────────┐\n",
      "│ params                          ┆ mean_test_score ┆ std_test_score ┆ rank_test_score │\n",
      "│ ---                             ┆ ---             ┆ ---            ┆ ---             │\n",
      "│ str                             ┆ f64             ┆ f64            ┆ i32             │\n",
      "╞═════════════════════════════════╪═════════════════╪════════════════╪═════════════════╡\n",
      "│ {'base_estimator__learning_rat… ┆ -0.751199       ┆ 0.164841       ┆ 1               │\n",
      "│ {'base_estimator__learning_rat… ┆ -0.751204       ┆ 0.164847       ┆ 2               │\n",
      "│ {'base_estimator__learning_rat… ┆ -0.754194       ┆ 0.163845       ┆ 3               │\n",
      "│ {'base_estimator__learning_rat… ┆ -0.754746       ┆ 0.164178       ┆ 4               │\n",
      "│ {'base_estimator__learning_rat… ┆ -0.790675       ┆ 0.164883       ┆ 5               │\n",
      "│ {'base_estimator__learning_rat… ┆ -0.79068        ┆ 0.164888       ┆ 6               │\n",
      "│ {'base_estimator__learning_rat… ┆ -0.849239       ┆ 0.138172       ┆ 7               │\n",
      "│ {'base_estimator__learning_rat… ┆ -0.849239       ┆ 0.138172       ┆ 8               │\n",
      "└─────────────────────────────────┴─────────────────┴────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Exécuter la recherche par grille avec tracking détaillé MLflow\n",
    "with mlflow.start_run(run_name=\"GB_Chain_GridSearch_Main\"):\n",
    "    print(\"Démarrage de la recherche d'hyperparamètres pour Gradient Boosting Chain...\")\n",
    "    \n",
    "    # Log des paramètres de la recherche\n",
    "    mlflow.log_param(\"cv_folds\", cv.n_splits)\n",
    "    mlflow.log_param(\"param_grid\", str(param_grid))\n",
    "    \n",
    "    # Exécuter la recherche\n",
    "    grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "    \n",
    "    # Afficher les meilleurs hyperparamètres\n",
    "    print(\"\\nMeilleurs hyperparamètres trouvés:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"Meilleur score RMSE (validation croisée): {-grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Log des meilleurs paramètres\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        mlflow.log_param(f\"best_{param}\", value)\n",
    "    \n",
    "    # Log du meilleur score\n",
    "    mlflow.log_metric(\"best_cv_rmse\", -grid_search.best_score_)\n",
    "    \n",
    "    # Convertir les résultats de GridSearch en DataFrame Polars\n",
    "    # Les résultats de GridSearch sont dans un dictionnaire que nous devons d'abord transformer\n",
    "    # car certains éléments comme les paramètres ne sont pas directement convertibles en Polars\n",
    "    cv_results_dict = {k: list(v) if isinstance(v, np.ndarray) else v \n",
    "                      for k, v in grid_search.cv_results_.items()}\n",
    "    \n",
    "    # Pour les objets de type non standard, convertir en string\n",
    "    for k, v in cv_results_dict.items():\n",
    "        if k == 'params':\n",
    "            cv_results_dict[k] = [str(param_dict) for param_dict in v]\n",
    "    \n",
    "    cv_results = pl.DataFrame(cv_results_dict)\n",
    "    \n",
    "    # Filtrer et trier les colonnes pertinentes\n",
    "    filtered_results = cv_results.select(\n",
    "        [\"params\", \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "    ).sort(\"rank_test_score\")\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    print(\"\\nRésultats des différentes combinaisons d'hyperparamètres:\")\n",
    "    print(filtered_results)\n",
    "    \n",
    "    # Conversion temporaire en pandas pour MLflow avec le bon format de paramètres\n",
    "    mlflow.log_table(data=filtered_results.to_pandas(), artifact_file=\"cv_results.json\")\n",
    "    \n",
    "    # Log des runs enfants pour chaque combinaison d'hyperparamètres\n",
    "    for i, row in enumerate(cv_results.iter_rows(named=True)):\n",
    "        mean_score = row[\"mean_test_score\"]\n",
    "        std_score = row[\"std_test_score\"]\n",
    "        rank = row[\"rank_test_score\"]\n",
    "        \n",
    "        # Récupérer les paramètres originaux (non convertis en string)\n",
    "        params = grid_search.cv_results_['params'][i]\n",
    "        params_str = \"_\".join([f\"{k.split('__')[-1]}={v}\" for k, v in params.items()])\n",
    "        \n",
    "        # Créer un run enfant pour cette combinaison\n",
    "        with mlflow.start_run(run_name=f\"Params_{params_str}\", nested=True):\n",
    "            # Log des paramètres\n",
    "            for param_name, param_value in params.items():\n",
    "                mlflow.log_param(param_name, param_value)\n",
    "            \n",
    "            # Log des métriques\n",
    "            mlflow.log_metric(\"mean_rmse\", -mean_score)\n",
    "            mlflow.log_metric(\"std_rmse\", std_score)\n",
    "            mlflow.log_metric(\"rank\", rank)\n",
    "            \n",
    "            # Log si c'est le meilleur modèle\n",
    "            is_best = (rank == 1)\n",
    "            mlflow.log_param(\"is_best_model\", is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performances du modèle optimisé sur l'ensemble de test:\n",
      "  attack: RMSE = 23.98, R² = 0.57\n",
      "  defense: RMSE = 24.48, R² = 0.34\n",
      "  sp_attack: RMSE = 16.35, R² = 0.85\n",
      "  sp_defense: RMSE = 17.70, R² = 0.10\n",
      "  speed: RMSE = 13.56, R² = 0.90\n",
      "  Moyenne: RMSE = 19.21, R² = 0.55\n",
      "\n",
      "Résumé des performances:\n",
      "shape: (5, 3)\n",
      "┌────────────┬───────────┬──────────┐\n",
      "│ Stat       ┆ RMSE      ┆ R²       │\n",
      "│ ---        ┆ ---       ┆ ---      │\n",
      "│ str        ┆ f64       ┆ f64      │\n",
      "╞════════════╪═══════════╪══════════╡\n",
      "│ attack     ┆ 23.983158 ┆ 0.56566  │\n",
      "│ defense    ┆ 24.481485 ┆ 0.33894  │\n",
      "│ sp_attack  ┆ 16.346381 ┆ 0.850748 │\n",
      "│ sp_defense ┆ 17.696512 ┆ 0.101748 │\n",
      "│ speed      ┆ 13.555917 ┆ 0.898879 │\n",
      "└────────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Récupérer le meilleur modèle trouvé\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Reconvertir les prédictions et les vraies valeurs à l'échelle originale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_true = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "# Évaluer les performances pour chaque stat\n",
    "print(\"\\nPerformances du modèle optimisé sur l'ensemble de test:\")\n",
    "metrics = {}\n",
    "rmse_values = []\n",
    "r2_values = []\n",
    "\n",
    "for i, col in enumerate(target_cols):\n",
    "    stat_name = col.replace('evolved_', '')\n",
    "    rmse = np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "    \n",
    "    rmse_values.append(rmse)\n",
    "    r2_values.append(r2)\n",
    "    \n",
    "    metrics[stat_name] = {\"RMSE\": rmse, \"R²\": r2}\n",
    "    print(f\"  {stat_name}: RMSE = {rmse:.2f}, R² = {r2:.2f}\")\n",
    "\n",
    "# Calculer les moyennes\n",
    "avg_rmse = np.mean(rmse_values)\n",
    "avg_r2 = np.mean(r2_values)\n",
    "print(f\"  Moyenne: RMSE = {avg_rmse:.2f}, R² = {avg_r2:.2f}\")\n",
    "\n",
    "# Créer un DataFrame Polars pour les résultats\n",
    "results_df = pl.DataFrame({\n",
    "    \"Stat\": list(metrics.keys()),\n",
    "    \"RMSE\": [metrics[stat][\"RMSE\"] for stat in metrics],\n",
    "    \"R²\": [metrics[stat][\"R²\"] for stat in metrics]\n",
    "})\n",
    "\n",
    "print(\"\\nRésumé des performances:\")\n",
    "print(results_df)\n",
    "\n",
    "# Enregistrer ces résultats dans MLflow\n",
    "with mlflow.start_run(run_name=\"Final_Model_Evaluation\"):\n",
    "    # Log des hyperparamètres\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        mlflow.log_param(param, value)\n",
    "    \n",
    "    # Log des métriques\n",
    "    for stat_name, values in metrics.items():\n",
    "        mlflow.log_metric(f\"{stat_name}_RMSE\", values[\"RMSE\"])\n",
    "        mlflow.log_metric(f\"{stat_name}_R2\", values[\"R²\"])\n",
    "    \n",
    "    mlflow.log_metric(\"average_RMSE\", avg_rmse)\n",
    "    mlflow.log_metric(\"average_R2\", avg_r2)\n",
    "    \n",
    "    # Log du modèle avec sa signature\n",
    "    from mlflow.models.signature import infer_signature\n",
    "    signature = infer_signature(X_test_scaled, y_pred_scaled)\n",
    "    mlflow.sklearn.log_model(best_model, \"final_model\", signature=signature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
