{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "silver_df = pl.read_csv('../data/silver_mega_evolutions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "    'evolved_attack', 'evolved_defense', \n",
    "    'evolved_sp_attack', 'evolved_sp_defense', 'evolved_speed'\n",
    "]\n",
    "\n",
    "input_cols = [col for col in silver_df.columns if col.startswith('base_')]\n",
    "\n",
    "# Préparer X et y\n",
    "X = silver_df.select(input_cols)\n",
    "y = silver_df.select(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(X_np, y_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler_X.fit_transform(X_train_np)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train_np)\n",
    "X_test_scaled = scaler_X.transform(X_test_np)\n",
    "y_test_scaled = scaler_y.transform(y_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": MultiOutputRegressor(GradientBoostingRegressor(random_state=42)),\n",
    "    \"Gradient Boosting Chain\": RegressorChain(GradientBoostingRegressor(random_state=42), \n",
    "                                             order=[0, 1, 2, 3, 4])  # 5 colonnes = indices 0-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/davidjbreau/projects/PKMN.DB/ml/evolution_prediction/notebooks/mlruns/347477286032186581', creation_time=1747857136449, experiment_id='347477286032186581', last_update_time=1747857136449, lifecycle_stage='active', name='mega_evolution_prediction', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importer MLflow pour le tracking des expériences\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Configurer l'expérience MLflow\n",
    "mlflow.set_experiment(\"mega_evolution_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entraînement de Decision Tree...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats pour Decision Tree:\n",
      "  attack: RMSE = 26.82, R² = 0.46\n",
      "  defense: RMSE = 31.84, R² = -0.12\n",
      "  sp_attack: RMSE = 41.14, R² = 0.05\n",
      "  sp_defense: RMSE = 16.83, R² = 0.19\n",
      "  speed: RMSE = 45.94, R² = -0.16\n",
      "  Average: RMSE = 32.51, R² = 0.08\n",
      "  --> Moyenne globale: RMSE = 32.51, R² = 0.08\n",
      "\n",
      "Entraînement de Random Forest...\n",
      "Résultats pour Random Forest:\n",
      "  attack: RMSE = 23.96, R² = 0.57\n",
      "  defense: RMSE = 23.65, R² = 0.38\n",
      "  sp_attack: RMSE = 29.65, R² = 0.51\n",
      "  sp_defense: RMSE = 17.03, R² = 0.17\n",
      "  speed: RMSE = 32.72, R² = 0.41\n",
      "  Average: RMSE = 25.40, R² = 0.41\n",
      "  --> Moyenne globale: RMSE = 25.40, R² = 0.41\n",
      "\n",
      "Entraînement de Gradient Boosting...\n",
      "Résultats pour Gradient Boosting:\n",
      "  attack: RMSE = 24.38, R² = 0.55\n",
      "  defense: RMSE = 22.29, R² = 0.45\n",
      "  sp_attack: RMSE = 14.35, R² = 0.88\n",
      "  sp_defense: RMSE = 17.86, R² = 0.09\n",
      "  speed: RMSE = 18.76, R² = 0.81\n",
      "  Average: RMSE = 19.53, R² = 0.56\n",
      "  --> Moyenne globale: RMSE = 19.53, R² = 0.56\n",
      "\n",
      "Entraînement de Gradient Boosting Chain...\n",
      "Résultats pour Gradient Boosting Chain:\n",
      "  attack: RMSE = 24.38, R² = 0.55\n",
      "  defense: RMSE = 23.59, R² = 0.39\n",
      "  sp_attack: RMSE = 14.56, R² = 0.88\n",
      "  sp_defense: RMSE = 18.71, R² = -0.00\n",
      "  speed: RMSE = 13.55, R² = 0.90\n",
      "  Average: RMSE = 18.96, R² = 0.54\n",
      "  --> Moyenne globale: RMSE = 18.96, R² = 0.54\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEntraînement de {name}...\")\n",
    "    \n",
    "    # Démarrer un run MLflow\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        # Entraînement\n",
    "        model.fit(X_train_scaled, y_train_scaled)\n",
    "        \n",
    "        # Prédictions\n",
    "        y_pred_scaled = model.predict(X_test_scaled)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "        y_true = scaler_y.inverse_transform(y_test_scaled)\n",
    "        \n",
    "        # Évaluation\n",
    "        metrics = {}\n",
    "        rmse_values = []\n",
    "        r2_values = []\n",
    "        \n",
    "        for i, col in enumerate(target_cols):\n",
    "            stat_name = col.replace('evolved_', '')\n",
    "            rmse = np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))\n",
    "            r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "            \n",
    "            # Collecter les valeurs pour calculer les moyennes\n",
    "            rmse_values.append(rmse)\n",
    "            r2_values.append(r2)\n",
    "            \n",
    "            # Enregistrer les métriques dans MLflow\n",
    "            mlflow.log_metric(f\"{stat_name}_RMSE\", rmse)\n",
    "            mlflow.log_metric(f\"{stat_name}_R2\", r2)\n",
    "            \n",
    "            metrics[stat_name] = {\"RMSE\": rmse, \"R²\": r2}\n",
    "        \n",
    "        # Calculer et enregistrer les métriques moyennes\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        avg_r2 = np.mean(r2_values)\n",
    "        \n",
    "        mlflow.log_metric(\"average_RMSE\", avg_rmse)\n",
    "        mlflow.log_metric(\"average_R2\", avg_r2)\n",
    "        \n",
    "        # Ajouter les moyennes aux métriques\n",
    "        metrics[\"Average\"] = {\"RMSE\": avg_rmse, \"R²\": avg_r2}\n",
    "        \n",
    "        # Créer la signature du modèle\n",
    "        from mlflow.models.signature import infer_signature\n",
    "        signature = infer_signature(X_train_scaled, y_train_scaled)\n",
    "        \n",
    "        # Log du modèle dans MLflow avec signature\n",
    "        mlflow.sklearn.log_model(model, name, signature=signature)\n",
    "        \n",
    "        # Afficher les résultats\n",
    "        print(f\"Résultats pour {name}:\")\n",
    "        for stat, vals in metrics.items():\n",
    "            print(f\"  {stat}: RMSE = {vals['RMSE']:.2f}, R² = {vals['R²']:.2f}\")\n",
    "        \n",
    "        # Mettre en évidence la métrique globale\n",
    "        print(f\"  --> Moyenne globale: RMSE = {avg_rmse:.2f}, R² = {avg_r2:.2f}\")\n",
    "        \n",
    "        results[name] = metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
